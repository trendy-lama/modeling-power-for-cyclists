---
title: "A Theory of Everything - for Cycling"
author: "trendy_lama"
output:
  word_document: default
  pdf_document: default
---
```{r}
power_curve = read.table("power_curve.csv", header = TRUE, sep = ",")
```

```{r}
plot(power_curve$time_sec, power_curve$power_watts, xlab = "Time in Seconds", ylab = "Max Average Power")
```

This concave up hyperbola is exactly what Monod and Scherrer (1965) predict. It has asymptotes at $t=0$ and $t=infinity$. Lets see how well a linear regression models this relationship.  

```{r}
watts_model = lm(power_watts ~ time_sec, data = power_curve)
summary(watts_model)
power_curve$watts_res = residuals(watts_model)
power_curve$watts_pred = predict(watts_model)
plot(power_curve$watts_pred, power_curve$watts_res, xlab = "Predicted Power", ylab = "Residuals")
```

This is not a good model for the data, unsurprisingly. Obviously linearity is violated here. The R-squared is very low and the residual standard error is 171 watts, which would make any prediction with this model useless. Accuracy for this model should be tighter to have any practical use. A sensible transformation is to transform the response variable from watts to $total work$ in joules. Since a watt is one joule per second, we can transform the model into $TW(t) = W' + CP*t$. *TW(t)* should be a linear function of time, which makes sense considering that muscles put out more work over time. Let's plot it and see if it looks linear like Monod and Scherrer (1965) predict.

```{r}
plot(power_curve$time_sec, power_curve$work_j, xlab = "Time in Seconds", ylab = "Work in Joules")
```

That looks like an excellent transformation. Let's be more precise and model it as a simple linear regression with time predicting total work.  

```{r}
joules_cp_model = lm(work_j ~ time_sec, data = power_curve)
summary(joules_cp_model)
```

The beta value for time (*CP*) is highly significant because it represents *CP*.The intercept is also highly significant and represents *W'*, the finite anaerobic work capacity. An important note here is that *W'* is in *joules*, while *CP* is in *watts* because the slope units of this relationship is in *joules/seconds* which is the definition of a *watt*.

The predicted values indicate that my threshold power is around 197 watts. My anaerobic potential is 46595 watts, which is impossible. The best sprinters in the world can put out a max of around 2000 watts. Looking at this dataset, I have put out a max of 1000 watts. This nonsensical value can be explained by the idiosyncrasies of the model. In real life, there is no power output at $t=0$ but fitting a function to the data adds predictions that do not make sense. Morton (1996) adds time constants and additional terms to correct for these impossible predictions at low values of *t*. The standard error for *CP* is 3 watts which is approximately a 1.5% error. This prediction can be used for practical purposes, however, it is not as good as an accurate FTP test. My actual FTP is around 250 watts. Estimating FTP from a critical power curve is notoriously inaccurate and usually leads to significant under-prediction even when using more accurate models.

Even though the predictor and intercept are highly significant and the R-squared value is extremely high, I will still check for any OLS assumption issues with our data. I expect linearity to be violated, but homosckedasticity and normality to be ok. I expect to see a funky residual plot. Since the data is time series, there is probably autocorrelation.

```{r}
power_curve$res = residuals(joules_cp_model)
power_curve$pred = predict(joules_cp_model)

plot(power_curve$pred, power_curve$res, pch = 19, xlab = "Predicted Work", ylab = "Residuals")
```

Normally, a pattern in the residuals would indicate that linearity is violated, but I suspect that this pattern can be explained by autocorrelation. homosckedasticity is ok, since there appears to be an equal number of residuals above and below zero. Normality will need to be tested by the Shapiro-Wilk test.  

```{r}
shapiro.test(power_curve$work_j)
```

Normality is violated, since H-not is rejected. This can be explained by either the data being from a non-iid sample or the autocorrelation. An iid sample is impractical because this model is for one specific rider and the data has to be time series. There appear to be a few points at high values of *t* that are having a large impact on our model. Lets check for outliers and high leverage points.  

```{r}
power_curve$leverage = hatvalues(joules_cp_model)
```

The high leverage cutoff for this dataset is >0.083. According to this criteria, there are four points that are considered high leverage. They all occur at high values of *t*: (t = 7200, 6300, 5400, 4200). This result does not surprise me, since all of these values were not maximum efforts for me.  Monod and Scherrer (1965) is also known to have issues at *t > 1800*. Let's check for any outliers but calculating the studentized residuals for these points. I expect t=7200 to be an outlier.

```{r}
require(MASS)
power_curve$stud_res = stdres(joules_cp_model)
qt(.025, 46)
```
I am concerned about the outlier at *t = 7200* which came in way below the model's prediction. This can be explained as not being a maximum effort because this value happened to be on a fast ride but not until exhaustion. Larger residuals make sense at these longer intervals because I have only done max efforts at a maximum of fifty five minutes. This model is also known to be inaccurate for any *t* value less than three minutes and greater than thirty minutes because it has not been adjusted to account for the asymptotic behavior of $Watts(t) = W'/t + CP$.

I doubt there will any serious problem with outliers. The critical value for a t distribution with 46 degress of freedom is 2.012. According to this criteria *t=7200* is considered an outlier, with a studentized residual of -5.13. I will remove this point to make our predictions more accurate, since it does not fit the criteria of a maximum effort. This may be problematic because I have a small sample size, but I expect *TW(t)* to be robust. Removing this point will not solve the autocorrelation, however. T and t-1 are likely positively correlated, but I will run a Durbin-Watson test to be precise.

```{r}
require(car)
durbinWatsonTest(joules_cp_model)
```

The Durbin-Watson test is significant, which means there is a problem with autocorrelation. There appears to be positive autocorrelation which makes sense considering that t-1 will be a good predictor for t and two of the regression conditions are violated. This does not necessarily need to be corrected, since the original linear adjustment fits the data extremely well. 

I will remove the outlier and rerun the regression.

```{r}
fixed_power_curve = read.table("power_curve_fixed.csv", header = TRUE, sep = ",")
fixed_joules_model = lm(work_j ~ time_sec, data = fixed_power_curve)
summary(fixed_joules_model)
```

The model with *t=7200* removed looks a bit better than the previous one. The residual standard error is lower, the R-squared is higher, and the F-stat is more significant. Lets correct the autocorrelation now.

```{r}
auto_joules_model = ar.ols(fixed_power_curve$work_j, order.max = 46, demean = F, intercept = T)
auto_joules_model
```

It appears that the optimal order for the autoregression is 23 which is impractical. However, I will create the suggested lagged variables to make the model more precise.  

```{r}
for(i in 1:23) {
lag = NA
lag[(i+1):47] = fixed_power_curve$work_j[1:(47-i)]
fixed_power_curve = cbind(fixed_power_curve, lag)
}

colnames(fixed_power_curve) = c("power_watts", "work_j", "time_sec", "lag1", "lag2", "lag3", "lag4", "lag5", "lag6", "lag7", "lag8", "lag9", "lag10", "lag11", "lag12", "lag13", "lag14", "lag15", "lag16", "lag17", "lag18", "lag19", "lag20", "lag21", "lag22", "lag23")
```

It seems like the larger lags are not significant because they correlate less with *t*. After playing around with partial F-tests I settled on this model with four lag predictors. Adding more predictors made the residual standard error rise without adding much predictive quality. Unfortunately, cross validation is not applicable here because of the lagged variables and small sample size, so I cannot find the optimal model.


```{r}
auto_regression = lm(work_j ~ lag1 + lag9 + lag10 + lag17, data = fixed_power_curve)
summary(auto_regression)
anova(auto_regression)
```

The residual standard error is around fifty percent lower and the R-squared acutally went up! 

Lets check the residual plot.

```{r}
fixed_power_curve$auto_res[24:47] = residuals(auto_regression)
fixed_power_curve$auto_pred[24:47] = predict(auto_regression)
plot(fixed_power_curve$auto_pred, fixed_power_curve$auto_res, xlab = "Predicted Work", ylab = "Residuals")
```

This plot looks much better!

Finally, lets see if the autocorrelation is fixed or is not a problem.

```{r}
durbinWatsonTest(auto_regression)
```

After correcting for autocorrelation, it seems like the model with lagged terms is the best at predicting total work. Also, the autocorrelation has been completely eliminated, since the Durbin-Watson test has a very high p-value and a test stat close to 2. However, it is not practical to use this model to make quick predictions necessary to give cyclists an edge, since total work is a function of lagged variables rather than time.

## Practical Uses
The practical use of this model is very simple. Take for instance, an athlete wants to do a twenty minute effort at eighty percent intensity. They can use this model to predict their twenty minute maximum power, take eighty percent for that prediction, then they know how many watts they have to average over that interval. This adds precision to training, where one can do intervals at different percents of their maximum average power.

Let's apply this analysis to predict points on my power curve that are not in the dataset with the joules_model. This simple model is not the most accurate but the logic will be easy to follow.

t = 1290
watts = 260

t = 195
watts = 366

```{r}
new_time = data.frame(time_sec=c(1290, 195))
predict(fixed_joules_model, newdata = new_time)
```

When we convert to watts, we get watts_hat = c(237.64, 404.06). These predictions are OK, the respective standardized residuals are 1.116 and 0.287. The reason why the standardized residuals are so low is because the residual standard error is high. To make this model more accurate, we need more statistical power and the more complex models of Morton (1996), and Alvarez (2002). Strava, Golden Cheeta, Cycling Analytics, and other cycling data platforms use some iteration of Monod and Scherrer (1965) - meaning that the original critical power model is still fundamentally useful.

